{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0aa227bc-b67c-4297-874e-9e72f9fca172",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import sys\n",
    "from importlib.resources import files\n",
    "\n",
    "import soundfile as sf\n",
    "import tqdm\n",
    "from cached_path import cached_path\n",
    "from hydra.utils import get_class\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from f5_tts.infer.utils_infer import (\n",
    "    infer_process,\n",
    "    load_model,\n",
    "    load_vocoder,\n",
    "    preprocess_ref_audio_text,\n",
    "    remove_silence_for_generated_wav,\n",
    "    save_spectrogram,\n",
    "    transcribe,\n",
    ")\n",
    "from f5_tts.model.utils import seed_everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "554992ca-8566-472c-b86c-f0281e0b98b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class F5TTS:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model=\"F5TTS_v1_Base\",\n",
    "        ckpt_file=\"\",\n",
    "        vocab_file=\"\",\n",
    "        ode_method=\"euler\",\n",
    "        use_ema=True,\n",
    "        vocoder_local_path=None,\n",
    "        device=None,\n",
    "        hf_cache_dir=None,\n",
    "    ):\n",
    "        model_cfg = OmegaConf.load(str(files(\"f5_tts\").joinpath(f\"configs/{model}.yaml\")))\n",
    "        model_cls = get_class(f\"f5_tts.model.{model_cfg.model.backbone}\")\n",
    "        model_arc = model_cfg.model.arch\n",
    "\n",
    "        self.mel_spec_type = model_cfg.model.mel_spec.mel_spec_type\n",
    "        self.target_sample_rate = model_cfg.model.mel_spec.target_sample_rate\n",
    "\n",
    "        self.ode_method = ode_method\n",
    "        self.use_ema = use_ema\n",
    "\n",
    "        if device is not None:\n",
    "            self.device = device\n",
    "        else:\n",
    "            import torch\n",
    "\n",
    "            self.device = (\n",
    "                \"cuda\"\n",
    "                if torch.cuda.is_available()\n",
    "                else \"xpu\"\n",
    "                if torch.xpu.is_available()\n",
    "                else \"mps\"\n",
    "                if torch.backends.mps.is_available()\n",
    "                else \"cpu\"\n",
    "            )\n",
    "\n",
    "        # Load models\n",
    "        self.vocoder = load_vocoder(\n",
    "            self.mel_spec_type, vocoder_local_path is not None, vocoder_local_path, self.device, hf_cache_dir\n",
    "        )\n",
    "\n",
    "        repo_name, ckpt_step, ckpt_type = \"F5-TTS\", 1250000, \"safetensors\"\n",
    "\n",
    "        # override for previous models\n",
    "        if model == \"F5TTS_Base\":\n",
    "            if self.mel_spec_type == \"vocos\":\n",
    "                ckpt_step = 1200000\n",
    "            elif self.mel_spec_type == \"bigvgan\":\n",
    "                model = \"F5TTS_Base_bigvgan\"\n",
    "                ckpt_type = \"pt\"\n",
    "        elif model == \"E2TTS_Base\":\n",
    "            repo_name = \"E2-TTS\"\n",
    "            ckpt_step = 1200000\n",
    "\n",
    "        if not ckpt_file:\n",
    "            ckpt_file = str(\n",
    "                cached_path(f\"hf://SWivid/{repo_name}/{model}/model_{ckpt_step}.{ckpt_type}\", cache_dir=hf_cache_dir)\n",
    "            )\n",
    "        \n",
    "        self.ema_model = load_model(\n",
    "            model_cls, model_arc, ckpt_file, self.mel_spec_type, vocab_file, self.ode_method, self.use_ema, self.device\n",
    "        )\n",
    "\n",
    "    def transcribe(self, ref_audio, language=None):\n",
    "        return transcribe(ref_audio, language)\n",
    "\n",
    "    def export_wav(self, wav, file_wave, remove_silence=False):\n",
    "        sf.write(file_wave, wav, self.target_sample_rate)\n",
    "\n",
    "        if remove_silence:\n",
    "            remove_silence_for_generated_wav(file_wave)\n",
    "\n",
    "    def export_spectrogram(self, spec, file_spec):\n",
    "        save_spectrogram(spec, file_spec)\n",
    "\n",
    "    def infer(\n",
    "        self,\n",
    "        ref_file,\n",
    "        ref_text,\n",
    "        gen_text,\n",
    "        show_info=print,\n",
    "        progress=tqdm,\n",
    "        target_rms=0.1,\n",
    "        cross_fade_duration=0.15,\n",
    "        sway_sampling_coef=-1,\n",
    "        cfg_strength=2,\n",
    "        nfe_step=32,\n",
    "        speed=1.0,\n",
    "        fix_duration=None,\n",
    "        remove_silence=False,\n",
    "        file_wave=None,\n",
    "        file_spec=None,\n",
    "        seed=None,\n",
    "    ):\n",
    "        if seed is None:\n",
    "            seed = random.randint(0, sys.maxsize)\n",
    "        seed_everything(seed)\n",
    "        self.seed = seed\n",
    "\n",
    "        ref_file, ref_text = preprocess_ref_audio_text(ref_file, ref_text)\n",
    "\n",
    "        wav, sr, spec = infer_process(\n",
    "            ref_file,\n",
    "            ref_text,\n",
    "            gen_text,\n",
    "            self.ema_model,\n",
    "            self.vocoder,\n",
    "            self.mel_spec_type,\n",
    "            show_info=show_info,\n",
    "            progress=progress,\n",
    "            target_rms=target_rms,\n",
    "            cross_fade_duration=cross_fade_duration,\n",
    "            nfe_step=nfe_step,\n",
    "            cfg_strength=cfg_strength,\n",
    "            sway_sampling_coef=sway_sampling_coef,\n",
    "            speed=speed,\n",
    "            fix_duration=fix_duration,\n",
    "            device=self.device,\n",
    "        )\n",
    "\n",
    "        if file_wave is not None:\n",
    "            self.export_wav(wav, file_wave, remove_silence)\n",
    "\n",
    "        if file_spec is not None:\n",
    "            self.export_spectrogram(spec, file_spec)\n",
    "\n",
    "        return wav, sr, spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63e652d3-c5fc-499d-8f11-fed32869dcc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download Vocos from huggingface charactr/vocos-mel-24khz\n",
      "\n",
      "vocab :  /workspace/F5-TTS/vocab.txt\n",
      "token :  custom\n",
      "model :  /workspace/F5-TTS/model_1250000.safetensors \n",
      "\n"
     ]
    }
   ],
   "source": [
    "f5tts = F5TTS(\n",
    "    ckpt_file=\"/workspace/F5-TTS/model_1250000.safetensors\",\n",
    "    vocab_file=\"/workspace/F5-TTS/vocab.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "275e517a-3402-4687-925e-c77a9fae8d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/F5-TTS/src/f5_tts/infer/examples/basic/basic_ref_en.wav'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(files(\"f5_tts\").joinpath(\"infer/examples/basic/basic_ref_en.wav\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e22e9e4-c3f8-41c8-8e29-5eff6af7467c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting audio...\n",
      "Using cached preprocessed reference audio...\n",
      "Using custom reference text...\n",
      "\n",
      "ref_text   I hate you so much. \n",
      "gen_text 0 I don't really care what you call me. I've been a silent spectator.\n",
      "\n",
      "\n",
      "Generating audio in 1 batches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7945713996887207\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "st = time.time()\n",
    "wav, sr, spec = f5tts.infer(\n",
    "    ref_file='/workspace/F5-TTS/voice.mp3',\n",
    "    ref_text=\"I hate you so much.\",\n",
    "    gen_text=\"\"\"I don't really care what you call me. I've been a silent spectator.\"\"\",\n",
    "    file_wave='/workspace/api_out.wav',\n",
    "    file_spec='/workspace/api_out.png',\n",
    "    seed=None,\n",
    "    nfe_step=16,\n",
    "    cfg_strength=2.0\n",
    ")\n",
    "print(time.time() - st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39350ef-89e2-4608-a36a-a29d4d9c4cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from audiotools import AudioSignal\n",
    "AudioSignal('/workspace/api_out.wav').widget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54764579-4bd3-426a-ba0e-4c490ab7cc7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
