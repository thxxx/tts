{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6369662a-7dad-4cf7-82a1-e77b9308b168",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import codecs\n",
    "import os\n",
    "import re\n",
    "from importlib.resources import files\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import tomli\n",
    "from cached_path import cached_path\n",
    "\n",
    "from infer.utils_infer import (\n",
    "    infer_process,\n",
    "    load_vocoder,\n",
    "    preprocess_ref_audio_text,\n",
    "    remove_silence_for_generated_wav,\n",
    ")\n",
    "from model import DiT, UNetT\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "# -----------------------------------------\n",
    "\n",
    "target_sample_rate = 24000\n",
    "n_mel_channels = 100\n",
    "hop_length = 256\n",
    "win_length = 1024\n",
    "n_fft = 1024\n",
    "mel_spec_type = \"vocos\"\n",
    "target_rms = 0.1\n",
    "cross_fade_duration = 0.15\n",
    "ode_method = \"euler\"\n",
    "nfe_step = 32  # 16, 32\n",
    "cfg_strength = 2.0\n",
    "sway_sampling_coef = -1.0\n",
    "speed = 1.0\n",
    "fix_duration = None\n",
    "\n",
    "# -----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec05191-3e7d-459c-88f2-170fb9139c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cls = DiT\n",
    "model_cfg = dict(dim=1024, depth=22, heads=16, ff_mult=2, text_dim=512, conv_layers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9108e8ec-72ca-4ae4-a9e6-bf99b3a58ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.utils import (\n",
    "    get_tokenizer,\n",
    "    convert_char_to_pinyin,\n",
    ")\n",
    "\n",
    "vocab_file = \"./infer/examples/vocab.txt\"\n",
    "tokenizer = \"custom\"\n",
    "\n",
    "vocab_char_map, vocab_size = get_tokenizer(vocab_file, tokenizer)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f5c3cc-f63a-4b54-b2f3-ec682e8df1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer=model_cls(**model_cfg, text_num_embeds=vocab_size, mel_dim=n_mel_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67d2e79-7c3b-44be-824f-8a859e548f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "ode_method = \"euler\"\n",
    "\n",
    "mel_spec_kwargs=dict(\n",
    "    n_fft=n_fft,\n",
    "    hop_length=hop_length,\n",
    "    win_length=win_length,\n",
    "    n_mel_channels=n_mel_channels,\n",
    "    target_sample_rate=target_sample_rate,\n",
    "    mel_spec_type=mel_spec_type,\n",
    ")\n",
    "\n",
    "odeint_kwargs=dict(\n",
    "    method=ode_method,\n",
    ")\n",
    "\n",
    "vocoder_name = \"vocos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e124592d-2a75-4b2b-a9ac-b56f0153932a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import CFM\n",
    "\n",
    "model = CFM(\n",
    "    transformer=transformer,\n",
    "    mel_spec_kwargs=mel_spec_kwargs,\n",
    "    odeint_kwargs=odeint_kwargs,\n",
    "    vocab_char_map=vocab_char_map,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00289a11-2fd3-4de4-ab0c-80c9131172ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = (\n",
    "    torch.float16 if \"cuda\" in device and torch.cuda.get_device_properties(device).major >= 6 else torch.float32\n",
    ")\n",
    "ckpt_path = \"/workspace/tts/ckpts/model_1200000.pt\"\n",
    "print(dtype)\n",
    "checkpoint = torch.load(ckpt_path, map_location=device, weights_only=True)\n",
    "use_ema = True\n",
    "\n",
    "if use_ema:\n",
    "    checkpoint[\"model_state_dict\"] = {\n",
    "        k.replace(\"ema_model.\", \"\"): v\n",
    "        for k, v in checkpoint[\"ema_model_state_dict\"].items()\n",
    "        if k not in [\"initted\", \"step\"]\n",
    "    }\n",
    "\n",
    "    # patch for backward compatibility, 305e3ea\n",
    "    for key in [\"mel_spec.mel_stft.mel_scale.fb\", \"mel_spec.mel_stft.spectrogram.window\"]:\n",
    "        if key in checkpoint[\"model_state_dict\"]:\n",
    "            del checkpoint[\"model_state_dict\"][key]\n",
    "\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"], strict=False)\n",
    "\n",
    "del checkpoint\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b298732-e505-40a9-88ce-10b4150f358a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_spec_type = vocoder_name\n",
    "if vocoder_name == \"vocos\":\n",
    "    vocoder_local_path = \"../checkpoints/vocos-mel-24khz\"\n",
    "elif vocoder_name == \"bigvgan\":\n",
    "    vocoder_local_path = \"../checkpoints/bigvgan_v2_24khz_100band_256x\"\n",
    "\n",
    "vocoder = load_vocoder(vocoder_name=mel_spec_type, is_local=True, local_path=\"/workspace/tts/src/f5_tts/vocoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3705fb-73d3-41e2-86a6-9005fd71f4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "\n",
    "adu, sr = torchaudio.load(ref_audio)\n",
    "print(adu.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b395e9-c188-4179-b681-1d32e80f44a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from audiotools import AudioSignal\n",
    "\n",
    "ref_audio = \"/workspace/dit_audio/valid_data/monster-saying-i-love-you-sound-effect-234404303_nw_prev.mp3\"\n",
    "ref_text = \"I love you.\"\n",
    "\n",
    "main_voice = {\n",
    "    \"ref_audio\": ref_audio,\n",
    "    \"ref_text\": ref_text,\n",
    "}\n",
    "\n",
    "voices = {\n",
    "    \"main\": main_voice\n",
    "}\n",
    "\n",
    "for voice in voices:\n",
    "    voices[voice][\"ref_audio\"], voices[voice][\"ref_text\"] = preprocess_ref_audio_text(\n",
    "        voices[voice][\"ref_audio\"], voices[voice][\"ref_text\"]\n",
    "    )\n",
    "    print(\"Voice:\", voice)\n",
    "    print(\"Ref_audio:\", voices[voice][\"ref_audio\"])\n",
    "    print(\"Ref_text:\", voices[voice][\"ref_text\"])\n",
    "\n",
    "AudioSignal(ref_audio).widget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2b0875-893f-49ee-85f1-32fe5ffb38d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "gen_text = \"Go kill them all. Get the fuck out of here!\"\n",
    "\n",
    "generated_audio_segments = []\n",
    "reg1 = r\"(?=\\[\\w+\\])\"\n",
    "chunks = re.split(reg1, gen_text)\n",
    "reg2 = r\"\\[(\\w+)\\]\"\n",
    "\n",
    "audio, final_sample_rate, spectragram = infer_process(\n",
    "    voices[voice][\"ref_audio\"],\n",
    "    voices[voice][\"ref_text\"], \n",
    "    gen_text, \n",
    "    model, \n",
    "    vocoder, \n",
    "    mel_spec_type=mel_spec_type, \n",
    "    speed=speed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98e9f1e-856b-4785-941d-728e44228792",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "gen_text = \"Go kill them all. Get the fuck out of here!\"\n",
    "\n",
    "generated_audio_segments = []\n",
    "reg1 = r\"(?=\\[\\w+\\])\"\n",
    "chunks = re.split(reg1, gen_text)\n",
    "reg2 = r\"\\[(\\w+)\\]\"\n",
    "\n",
    "audio, final_sample_rate, spectragram = infer_process(\n",
    "    None,\n",
    "    \" \",\n",
    "    gen_text, \n",
    "    model, \n",
    "    vocoder, \n",
    "    mel_spec_type=mel_spec_type, \n",
    "    speed=speed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7127184-62e8-49fa-b192-df3cb880fb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from audiotools import AudioSignal\n",
    "\n",
    "AudioSignal(audio, sample_rate=24000).widget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72e0da2-29e1-4d83-a0c4-7793faf83ba6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
